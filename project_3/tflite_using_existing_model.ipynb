{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2\", 224, 1280)\n",
    "handle_base, pixels, FV_SIZE = module_selection\n",
    "MODULE_HANDLE=\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = (\"train[:80]\", \"train[:10]\", \"train[:10]\")\n",
    "splits, info = tfds.load('cats_vs_dogs',with_info=True, as_supervised=True, split = splits)\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_examples = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 224, 224, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fine_tuning=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
    "                                   input_shape=IMAGE_SIZE + (3,), \n",
    "                                   output_shape=[FV_SIZE],\n",
    "                                   trainable=do_fine_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "model = tf.keras.Sequential([feature_extractor,\n",
    "                            tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 10\n",
    "if do_fine_tuning:\n",
    "    feature_extractor.trainable=True\n",
    "    \n",
    "    for layer in model.layers[-NUM_LAYERS:]:\n",
    "        layer.trainable=True\n",
    "else:\n",
    "    feature_extractor.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_fine_tuning:\n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "else:\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7379 - accuracy: 0.6125 - val_loss: 0.5886 - val_accuracy: 0.8000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 0.4316 - accuracy: 0.8250 - val_loss: 0.3812 - val_accuracy: 0.8000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 0.2540 - accuracy: 0.9000 - val_loss: 0.2570 - val_accuracy: 0.8000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 0.1490 - accuracy: 0.9625 - val_loss: 0.1798 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 1s 421ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "hist = model.fit(train_batches,\n",
    "                epochs = EPOCHS,\n",
    "                validation_data= validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATS_VS_DOGS_SAVED_MODEL = 'exp_saved_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/itstimetogetout/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/itstimetogetout/Library/Python/3.7/lib/python/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['keras_layer_input'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 224, 224, 3)\n",
      "      name: serving_default_keras_layer_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 2)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $CATS_VS_DOGS_SAVED_MODEL\n",
    "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(CATS_VS_DOGS_SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n",
      "((), {'keras_layer_input': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_layer_input')})\n",
      "{'dense': TensorSpec(shape=(None, 2), dtype=tf.float32, name='dense')}\n"
     ]
    }
   ],
   "source": [
    "print(list(loaded.signatures.keys()))\n",
    "infer = loaded.signatures['serving_default']\n",
    "print(infer.structured_input_signature)\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
